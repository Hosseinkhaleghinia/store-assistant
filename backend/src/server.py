"""
Store Assistant Backend Server (FastAPI)
Handles text and voice chat requests with optional TTS output.
"""

import os
import shutil
import uuid
import logging
from typing import Optional

from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from pydantic import BaseModel
from langchain_core.messages import HumanMessage, AIMessage
from dotenv import load_dotenv

from rag_agent import (
    load_vector_stores, 
    create_retriever_tools, 
    create_agent_graph, 
    transcribe_audio_file
)
from config import Colors

# Load environment variables
load_dotenv()

# ============================================
# FastAPI Application Setup
# ============================================
app = FastAPI(title="Store Assistant API", version="1.0.0")

# CORS configuration (restrict origins in production)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Logging configuration
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("API")

# Global agent instance
agent = None


# ============================================
# Request/Response Models
# ============================================
class ChatRequest(BaseModel):
    """Text chat request model"""
    message: str
    thread_id: str
    enable_tts: bool = False


class ChatResponse(BaseModel):
    """Chat response model with optional audio URL"""
    response: str
    status: str
    audio_url: Optional[str] = None


# ============================================
# Startup Event
# ============================================
@app.on_event("startup")
async def startup_event():
    """
    Initialize agent on server startup.
    Loads vector stores and creates agent graph.
    """
    global agent
    logger.info("ğŸš€ Starting Store Assistant Server...")
    
    # Load databases and create graph
    products_store, articles_store = load_vector_stores()
    products_tool, articles_tool = create_retriever_tools(products_store, articles_store)
    agent = create_agent_graph(products_tool, articles_tool)
    
    logger.info("âœ… Agent initialized and ready.")


# ============================================
# Helper Functions
# ============================================
async def run_agent(inputs: dict, thread_id: str) -> tuple[str, Optional[str]]:
    """
    Execute agent graph and return text response + audio path.
    
    Args:
        inputs: Agent input dictionary (messages, audio_path, enable_tts, etc.)
        thread_id: Conversation thread identifier
        
    Returns:
        tuple: (response_text, audio_path)
    """
    config = {"configurable": {"thread_id": thread_id}}
    final_response = ""
    audio_path = None
    
    try:
        # Stream graph execution
        for event in agent.stream(inputs, config=config, stream_mode="values"):
            current_messages = event.get("messages", [])
            if not current_messages:
                continue
                
            last_message = current_messages[-1]
            if isinstance(last_message, AIMessage):
                final_response = last_message.content
        
        # Extract audio path from final state
        final_state = agent.get_state(config)
        if final_state and "audio_output_path" in final_state.values:
            audio_path = final_state.values.get("audio_output_path")
                
        return final_response if final_response else "Sorry, no response received.", audio_path
        
    except Exception as e:
        logger.error(f"Error executing graph: {e}")
        return "An error occurred during processing.", None


# ============================================
# API Endpoints
# ============================================
@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    """
    Handle text chat messages.
    
    Body:
        - message: User's text message
        - thread_id: Conversation thread ID
        - enable_tts: Enable text-to-speech output (default: False)
        
    Returns:
        ChatResponse with text response and optional audio URL
    """
    logger.info(f"ğŸ“© Text Message: {request.message[:50]}... (TTS: {request.enable_tts})")
    
    inputs = {
        "messages": [HumanMessage(content=request.message)],
        "audio_path": None,
        "enable_tts": request.enable_tts,
        "audio_output_path": None,
    }
    
    response_text, audio_path = await run_agent(inputs, request.thread_id)
    
    # Build audio URL if file exists
    audio_url = None
    if audio_path and os.path.exists(audio_path):
        filename = os.path.basename(audio_path)
        audio_url = f"/audio/{filename}"
    
    return ChatResponse(
        response=response_text, 
        status="success",
        audio_url=audio_url
    )


@app.post("/voice", response_model=ChatResponse)
async def voice_endpoint(
    file: UploadFile = File(...),
    thread_id: str = Form(...),
    enable_tts: bool = Form(False)
):
    """
    Handle voice messages.
    Transcribes audio and processes through agent.
    
    Form Data:
        - file: Audio file (mp3, ogg, wav, webm)
        - thread_id: Conversation thread ID
        - enable_tts: Enable text-to-speech output (default: False)
        
    Returns:
        ChatResponse with text response and optional audio URL
    """
    logger.info(f"ğŸ¤ Voice Message (TTS: {enable_tts})")
    
    file_ext = file.filename.split(".")[-1]
    temp_filename = f"temp_{uuid.uuid4()}.{file_ext}"
    
    try:
        # Save uploaded file temporarily
        with open(temp_filename, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
            
        inputs = {
            "messages": [],
            "audio_path": temp_filename,
            "enable_tts": enable_tts
        }
        
        response_text, audio_path = await run_agent(inputs, thread_id)
        
        # Clean up temp file
        os.remove(temp_filename)
        
        # Build audio URL if file exists
        audio_url = None
        if audio_path and os.path.exists(audio_path):
            filename = os.path.basename(audio_path)
            audio_url = f"/audio/{filename}"
        
        return ChatResponse(
            response=response_text,
            status="success",
            audio_url=audio_url
        )
        
    except Exception as e:
        logger.error(f"Voice error: {e}")
        if os.path.exists(temp_filename):
            os.remove(temp_filename)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/audio/{filename}")
async def get_audio_file(filename: str):
    """
    Serve generated audio files.
    
    Args:
        filename: Audio file name
        
    Returns:
        Audio file response
    """
    file_path = os.path.join("backend/data/audio", filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="Audio file not found")
    
    return FileResponse(
        file_path,
        media_type="audio/wav",
        filename=filename
    )


# ============================================
# Run Server
# ============================================
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8005)



# """
# Store Assistant Backend Server (FastAPI)
# """

# import os
# import shutil
# import uuid
# import logging
# from typing import Optional
# from fastapi import FastAPI, UploadFile, File, Form, HTTPException
# from fastapi.middleware.cors import CORSMiddleware
# from fastapi.responses import JSONResponse, FileResponse  # ğŸ†• Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
# from pydantic import BaseModel
# from langchain_core.messages import HumanMessage, AIMessage
# from dotenv import load_dotenv


# # Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ú©Ø±Ø¯Ù† Ù…Ù†Ø·Ù‚ Ø§ÛŒØ¬Ù†Øª Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ
# from rag_agent import (
#     load_vector_stores, 
#     create_retriever_tools, 
#     create_agent_graph, 
#     transcribe_audio_file
# )
# from config import Colors

# # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø§Ø² ÙØ§ÛŒÙ„ .env
# load_dotenv()

# # 1. Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ FastAPI
# app = FastAPI(title="Store Assistant API", version="1.0.0")

# # 2. ØªÙ†Ø¸ÛŒÙ…Ø§Øª CORS (Ø­ÛŒØ§ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ React)
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],  # Ø¯Ø± Ù¾Ø±ÙˆØ¯Ø§Ú©Ø´Ù† Ø¨Ù‡ Ø¢Ø¯Ø±Ø³ Ø¯Ù‚ÛŒÙ‚ ÙØ±Ø§Ù†Øª Ù…Ø­Ø¯ÙˆØ¯ Ú©Ù†ÛŒØ¯
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

# # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯ÛŒÙ†Ú¯
# logging.basicConfig(level=logging.INFO)
# logger = logging.getLogger("API")

# # Ù…ØªØºÛŒØ± Ø³Ø±Ø§Ø³Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ¬Ù†Øª
# agent = None

# # 3. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ/Ø®Ø±ÙˆØ¬ÛŒ
# class ChatRequest(BaseModel):
#     message: str
#     thread_id: str
#     enable_tts: bool = False  # ğŸ†• Ù¾Ø§Ø±Ø§Ù…ØªØ± Ú©Ù†ØªØ±Ù„ TTS    

# class ChatResponse(BaseModel):
#     response: str
#     status: str
#     audio_url: Optional[str] = None  # ğŸ†• Ù„ÛŒÙ†Ú© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ

# # 4. Ø±ÙˆÛŒØ¯Ø§Ø¯ Ø´Ø±ÙˆØ¹ Ø¨Ø±Ù†Ø§Ù…Ù‡
# @app.on_event("startup")
# async def startup_event():
#     global agent
#     logger.info("ğŸš€ Starting Store Assistant Server...")
    
#     # Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ùˆ Ú¯Ø±Ø§Ù (Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù…Ø«Ù„ rag_agent.py)
#     products_store, articles_store = load_vector_stores()
#     products_tool, articles_tool = create_retriever_tools(products_store, articles_store)
#     agent = create_agent_graph(products_tool, articles_tool)
    
#     logger.info("âœ… Agent initialized and ready.")

# # 5. ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ú¯Ø±Ø§Ù
# async def run_agent(inputs: dict, thread_id: str) -> tuple[str, Optional[str]]:
#     """
#     Ø§Ø¬Ø±Ø§ÛŒ Ú¯Ø±Ø§Ù Ùˆ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù¾Ø§Ø³Ø® Ù…ØªÙ†ÛŒ + Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
    
#     Returns:
#         (response_text, audio_path)
#     """
#     config = {"configurable": {"thread_id": thread_id}}
#     final_response = ""
#     audio_path = None
    
#     try:
#         # Ø§Ø¬Ø±Ø§ÛŒ Ú¯Ø±Ø§Ù
#         for event in agent.stream(inputs, config=config, stream_mode="values"):
#             current_messages = event.get("messages", [])
#             if not current_messages:
#                 continue
                
#             last_message = current_messages[-1]
#             if isinstance(last_message, AIMessage):
#                 final_response = last_message.content
        
#         # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø² state
#         # Ø¨Ø§ÛŒØ¯ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† state Ø¨Ú¯ÛŒØ±ÛŒÙ…
#         final_state = agent.get_state(config)
#         if final_state and "audio_output_path" in final_state.values:
#             audio_path = final_state.values.get("audio_output_path")
                
#         return final_response if final_response else "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ù¾Ø§Ø³Ø®ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.", audio_path
        
#     except Exception as e:
#         logger.error(f"Error executing graph: {e}")
#         return "Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø® Ø¯Ø§Ø¯.", None

# # 6. Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª Ú†Øª Ù…ØªÙ†ÛŒ
# @app.post("/chat", response_model=ChatResponse)
# async def chat_endpoint(request: ChatRequest):
#     logger.info(f"ğŸ“© Text Message: {request.message[:50]}... (TTS: {request.enable_tts})")
    
#     inputs = {
#         "messages": [HumanMessage(content=request.message)],
#         "audio_path": None,
#         "enable_tts": request.enable_tts,  # ğŸ†• Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ú¯Ø±Ø§Ù
#         "audio_output_path": None,
#     }
    
#     response_text, audio_path = await run_agent(inputs, request.thread_id)
    
#     # Ø³Ø§Ø®Øª URL Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
#     audio_url = None
#     if audio_path and os.path.exists(audio_path):
#         filename = os.path.basename(audio_path)
#         audio_url = f"/audio/{filename}"
    
#     return ChatResponse(
#         response=response_text, 
#         status="success",
#         audio_url=audio_url  # ğŸ†•
#     )
# # 7. Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ
# @app.post("/voice", response_model=ChatResponse)
# async def voice_endpoint(
#     file: UploadFile = File(...),
#     thread_id: str = Form(...),
#     enable_tts: bool = Form(False)  # ğŸ†• Ù¾Ø§Ø±Ø§Ù…ØªØ± Ø§Ø®ØªÛŒØ§Ø±ÛŒ
# ):
#     logger.info(f"ğŸ¤ Voice Message (TTS: {enable_tts})")
    
#     file_ext = file.filename.split(".")[-1]
#     temp_filename = f"temp_{uuid.uuid4()}.{file_ext}"
    
#     try:
#         with open(temp_filename, "wb") as buffer:
#             shutil.copyfileobj(file.file, buffer)
            
#         inputs = {
#             "messages": [],
#             "audio_path": temp_filename,
#             "enable_tts": enable_tts  # ğŸ†•
#         }
        
#         response_text, audio_path = await run_agent(inputs, thread_id)
        
#         os.remove(temp_filename)
        
#         audio_url = None
#         if audio_path and os.path.exists(audio_path):
#             filename = os.path.basename(audio_path)
#             audio_url = f"/audio/{filename}"
        
#         return ChatResponse(
#             response=response_text,
#             status="success",
#             audio_url=audio_url  # ğŸ†•
#         )
        
#     except Exception as e:
#         logger.error(f"Voice error: {e}")
#         if os.path.exists(temp_filename):
#             os.remove(temp_filename)
#         raise HTTPException(status_code=500, detail=str(e))

# # ğŸ†• Ø§Ù†Ø¯Ù¾ÙˆÛŒÙ†Øª Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ùˆ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØµÙˆØªÛŒ
# @app.get("/audio/{filename}")
# async def get_audio_file(filename: str):
#     """
#     Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡
#     """
#     file_path = os.path.join("backend/data/audio", filename)
    
#     if not os.path.exists(file_path):
#         raise HTTPException(status_code=404, detail="Audio file not found")
    
#     return FileResponse(
#         file_path,
#         media_type="audio/wav",
#         filename=filename
#     )

# # Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§: uvicorn server:app --reload --port 8000
# if __name__ == "__main__":
#     import uvicorn
#     uvicorn.run(app, host="127.0.0.1", port=8005)